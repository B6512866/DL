# ============================================
# Cell 9: Train the Model (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß)
# ============================================
import tensorflow as tf

# Calculate steps per epoch
def calculate_steps(captions, batch_size):
    """Calculate number of steps per epoch"""
    total = 0
    for image_id, caption_list in captions.items():
        for caption in caption_list:
            total += len(caption.split()) - 1
    return total // batch_size

batch_size = 32
epochs = 20

steps = calculate_steps(train_captions, batch_size)
print(f"Steps per epoch: {steps}")

# Callbacks
checkpoint = ModelCheckpoint('best_model.keras', 
                            monitor='loss', 
                            verbose=1, 
                            save_best_only=True, 
                            mode='min')

early_stop = EarlyStopping(monitor='loss', 
                          patience=3, 
                          verbose=1, 
                          restore_best_weights=True)

# ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á generator wrapper ‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á dtype ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
def generator_wrapper():
    gen = data_generator(train_captions, features, tokenizer, max_length, vocab_size, batch_size)
    for (X1, X2), y in gen:
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô dtype ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
        X1 = X1.astype('float32')  # Image features
        X2 = X2.astype('int32')    # Sequences
        y = y.astype('float32')    # One-hot labels
        yield (X1, X2), y

# ‡∏™‡∏£‡πâ‡∏≤‡∏á tf.data.Dataset ‡∏à‡∏≤‡∏Å generator
dataset = tf.data.Dataset.from_generator(
    generator_wrapper,
    output_signature=(
        (
            tf.TensorSpec(shape=(None, 4096), dtype=tf.float32),      # Image features
            tf.TensorSpec(shape=(None, max_length), dtype=tf.int32)   # Sequences (int32)
        ),
        tf.TensorSpec(shape=(None, vocab_size), dtype=tf.float32)     # One-hot output
    )
)

# Train model
print("\nüöÄ Starting training...")
print(f"Total steps per epoch: {steps}")
print(f"Batch size: {batch_size}")
print(f"Epochs: {epochs}")
print("\n‚ö†Ô∏è  This will take a long time! Consider reducing epochs if testing.\n")

history = model.fit(
    dataset,
    epochs=epochs,
    steps_per_epoch=steps,
    callbacks=[checkpoint, early_stop],
    verbose=1
)

# Save final model
model.save('final_model.keras')
print("\n‚úÖ Training complete! Model saved as 'final_model.keras'")
